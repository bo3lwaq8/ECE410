# CUDA Vector Addition Performance Analysis

This project analyzes the performance of a simple vector addition algorithm on an NVIDIA GPU using CUDA C++. It measures the execution time for various matrix sizes and visualizes the results to highlight the difference between total execution time and kernel-only computation time.

## Project Files
- `cuda_timing.cu`: The CUDA C++ source code that runs the vector addition simulation and measures performance.
- `plot_results.py`: A Python script that uses Matplotlib to generate a bar chart from the simulation results.
- `performance_chart.png`: The output bar chart generated by the Python script.

## How to Run

### Prerequisites
- An NVIDIA GPU
- The NVIDIA CUDA Toolkit (with `nvcc` compiler)
- Python 3
- Matplotlib (`pip install matplotlib`)

### Instructions

1.  **Compile the CUDA Code:**
    Open a terminal and run the `nvcc` compiler to create an executable.
    ```bash
    nvcc cuda_timing.cu -o cuda_timing
    ```

2.  **Run the Simulation:**
    Execute the compiled program. This will run the simulation and print a table of timing results to the console.
    ```bash
    ./cuda_timing
    ```
    (On Windows, run `cuda_timing.exe`)

3.  **Generate the Plot:**
    Copy the entire output table from the terminal. Open the `plot_results.py` file and paste the data into the `data` dictionary, replacing the placeholder values. Then, run the script.
    ```bash
    python plot_results.py
    ```
    This will display the performance chart and save it as `performance_chart.png`.

## Analysis of Results

![Performance Chart](performance_chart.png)

The performance chart reveals several key insights into GPU computing:

1.  **GPU Warm-up Cost:** The first run (at `2^15`) shows an unusually high execution time. This is due to the one-time cost of initializing the CUDA context and driver. All subsequent runs show the normal operating performance.

2.  **Memory Transfer is the Bottleneck:** The "Total Time" is significantly higher than the "Kernel Execution Time Only". This demonstrates that the primary performance limitation is not the speed of the GPU's computation, but the time it takes to transfer data between the CPU's main memory and the GPU's memory.

3.  **Extreme Kernel Speed:** The actual computation time on the GPU (the kernel execution) is extremely low, often measuring in microseconds. This highlights the massive parallel processing power of the GPU for tasks like vector addition.